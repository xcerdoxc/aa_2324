{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78hwtX74aaeN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X7Njio92KFR"
   },
   "source": [
    "# FCN\n",
    "\n",
    "Avui farem feina amb xarxes que no tenen cap tipus de capa _fully connected_ per tant serà una xarxa _Fully Convolutional Network_ (FCN). Quan parlam d'una xarxa FCN, ens referim a xarxes tipus VGG. Ens anirà molt bé fer aquesta pràctica per poder passar a xarxes que fan segmentació ja que la meitat d'aquestes és una FCN.\n",
    "\n",
    "Emprarem un dataset propi per fer aquesta pràctica. Això implica fer una mica més de feina per preparar les dades. En concret emprarem una versió del conjunt de dades : AIXI_SHAPE propi d'en Miquel Miró. [Enllaç](https://uibes-my.sharepoint.com/:u:/g/personal/gma040_id_uib_eu/EcsNAK5mkXRBqayDo1JYeooBWCf1lpRA-YJHT_kDF4J_nA?e=apkCql)\n",
    "\n",
    "La feina d'avui és \"lliure\" (considerau-ho una mini-pràctica), el conjunt de dades que teniu a la vostra disposició permet fer com a mínim 4 feines:\n",
    "\n",
    "1. **Regressió**: Contar quants d'objectes hi ha\n",
    "2. **Regressió de classe**: Contar quants d'objectes de cada classe hi ha en una imatge.\n",
    "3. **Detecció**: Mostrar on hi ha cada un dels objectes. Es podrien emprar xarxes ja fetes per aquesta tasca (tant les que teniu disponibles a pytorch com altres que trobeu)\n",
    "4. **Segmentació**: Encara no en sabem, però ho resoldrem la setmana que vé.\n",
    "\n",
    "Avui heu de fer una de les dues primeres. Tant podeu triar fer-ho amb les imatges amb textura, com amb les imatges binaries que serveixen com a _ground truth_ (gt).\n",
    "\n",
    "Les imatges del gt són imatges binàries (0,1) de 3 canals on a cada canal hi ha un tipus d'objecte . Per poder contar el nombre d'objectes possiblement haureu de emprar les funcions `cv2.add` per unir tots els canals en una sola imatge i la funció `cv2.findContours` per contar el nombre d'objectes en una imatge. A més podeu demanar-me ajuda a mi o al vostre amic ChatGPT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### [Inciso] Si emprau Colab:\n",
    "\n",
    "Aquest codi us serveix per connectar colab amb google drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGq0Ys7EGSTs",
    "outputId": "0639e06a-4fdb-4191-9aff-2715abc80ecf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkUHh4I4HyEQ",
    "outputId": "c8670a2f-1365-4943-ca58-4f6cd68bc40c"
   },
   "outputs": [],
   "source": [
    "%ls\n",
    "%cd #TODO al vostre sistema de fitxers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IUXSYLw07AV"
   },
   "source": [
    "## Preparació de les Dades\n",
    "Per preparar el conjunt de dades necessitarem fer algunes pases:\n",
    "\n",
    "1. Crear una llista amb les imatges \n",
    "2. Crear una classe que ens permeti obtenir una tupla (imatge, etiqueta)\n",
    "3. Emprar els objectes DataLoader com hem fet sempre, aquí no trobareu cap canvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear una llista amb les imatges \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvBbWj9BZONG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_train = ## TODO: posar el vostre path\n",
    "\n",
    "files = os.listdir(path_train)\n",
    "img_files = list([f\"{path_train}{p}\" for p in files if p.endswith('.png')])\n",
    "label_files = list([f\"{path_train}gt/{p}\" for p in files if p.endswith('.png')])\n",
    "\n",
    "## TODO: Comprovar que img_files i label_files tenen la informació del path de cada imatge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B2JRO5T1ZiS"
   },
   "source": [
    "#### Crear una classe que ens permeti obtenir una tupla (imatge, etiqueta)\n",
    "\n",
    "Aquesta classe hereta de la superclasse _Dataset_ i com a mínim ha de tenir els mètodes:\n",
    "\n",
    "1. `__len__(self)`: retorna la longitud del dataset\n",
    "2. `__getitem__(self, index)`: retorna l'element que es troba a la posició marcada pel valor d'index. Quan parlam d'un element parlam de la imatge i de la seva etiqueta.\n",
    "\n",
    "El constructor i els atributs de la classe els he decidit jo:\n",
    "\n",
    "- Llista amb els _paths_ a les imatges\n",
    "- Llista amb els _paths_ a les imatges de gt que ens serviràn per calcular l'etiqueta de la imatge\n",
    "- Un objecte transform\n",
    "\n",
    "A la classe podeu afegir tants mètodes públics i privats com necessiteu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiVfQJ0ZbzD0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constructor del dataset.\n",
    "class AIXI_Shape(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        super().__init__()\n",
    "        self.paths = images\n",
    "        self.labels = labels\n",
    "        self.len = len(self.paths)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        image = ## llegir la imatge que és al path\n",
    "\n",
    "        label = None\n",
    "        return (image, label)\n",
    "\n",
    "# image normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ## Si voleu posar alguna cosa aquí, és feina vostrs\n",
    "])\n",
    "\n",
    "\n",
    "# creació dels conjunts d'entrenament i test\n",
    "train_ds = AIXI_Shape(img_files, label_files, transform)\n",
    "# El test l'heu de crear vosaltres\n",
    "train_dl = DataLoader(train_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUKSc7YL3kNK"
   },
   "source": [
    "## Xarxa\n",
    "Com sempre, vosaltres us encarregau de dissenyar la xarxa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo2R5YE8ifMP"
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        #TODO definir la xarxa.\n",
    "\n",
    "        # Ajuda: A la darrera capa convolucional estaría molt bé que: out_channels = al nombre de sortides de la xarxa\n",
    "           \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # TODO\n",
    "        # Ajuda: no hi pot haver nombre de cel·lules negatius ;)\n",
    "        return x.squeeze() # Aquesta funció en servirà per eliminar dimensions de mida 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQVfN-vD3uPF"
   },
   "source": [
    "# Entrenament\n",
    "\n",
    "El blucle d'entrenament és el de sempre. Només heu de pensar quina funció de pèrdua heu d'emprar per el vostre/nostre problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WqMHALIoN1c"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "      \n",
    "        loss = # TODO\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            test_loss += #TODO\n",
    "          \n",
    "   \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3yxe2hX4eGc"
   },
   "source": [
    "## Entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jGCuUhwoR7A"
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = # TODO\n",
    "lr = #TODO\n",
    "\n",
    "model = MyNet().to(device)\n",
    "\n",
    "\n",
    "optimizer = # TODO\n",
    "\n",
    "# Guardam el valor de pèrdua mig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_dl, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaBP84cn4tPK"
   },
   "source": [
    "## Validació\n",
    "\n",
    "Heu de fer vosaltres la validació depenent del problema que voldreu resoldre"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
