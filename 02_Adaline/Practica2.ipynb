{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629fbe0b",
   "metadata": {},
   "source": [
    "# Pràctica 2 - Perceptron\n",
    "\n",
    "**Adaline: Batch i Stochastic gradient descent**\n",
    "\n",
    "ADAptative Linear NEuron (Adaline) representa un algorisme diferent al presentat per Rosenblatt per xarxes d'una sola neurona.\n",
    "\n",
    "Aquest algorisme és important, ja que mostra el concepte de _definició i minimització de funcions de cost_. La difèrencia entre Adaline i el perceptron presentat per Rosenblatt és que els pesos de la neurona s'actualitzen mitjançant una funció d'activació lineal en lloc d'una funció escaló.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1b04f",
   "metadata": {},
   "source": [
    "## Teoría bàsica\n",
    "\n",
    "La **funció d'activació lineal** $\\phi(z)$ és la funció identitat de l'entrada de la xarxa: $\\phi(w^Tx) = w^Tx$, aquesta funció és la que s'empra per aprendre els pesos de la xarxa. Per altra banda, utilitzarem una funció similar a la funció escaló per determinar la classe d'una mostra.\n",
    "\n",
    "La **funció objectiu**, és a dir, aquella que volem optimitzar, és una funció de cost que volem minimitzar. En aquest cas és la funció $J$ que aprèn els pesos com la suma dels errors quadrats:  $$J(w) = 1/2\\sum_i(y^{(i)} - \\phi(z^{(i)}))^2$$\n",
    "\n",
    "L'ús d'aquesta funció contínua vé motivada perquè aquesta és diferenciable i convexa. Això implica que podem aplicar l'algorisme del **descens de gradient** per trobar els pesos que la minimitzen.\n",
    "\n",
    "\n",
    "![image](imatges/02_minimitzacio.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedc56b",
   "metadata": {},
   "source": [
    "## Algorisme\n",
    "\n",
    "L'algorisme es resumeix en les següents pases:\n",
    "\n",
    "1. Inicialitzar els pesos a valor 0 (o a nombre aleatori prou petit).\n",
    "2. Fer $n$ iteracions on, a cada iteració ajustarem els pesos:\n",
    "\n",
    "    - Per cada element, $x^{(i)}$, del conjunt que emprarem per entrenar fer:\n",
    "\n",
    "        1. Calcular el valor de sortida de la xarxa $\\hat y$ (**no la predicció**).\n",
    "        2. Actualitzar el vector de pesos, $\\mathbf{w}$.\n",
    "\n",
    "\n",
    "3. Calcular la classe de sortida (predicció) *final* de la xarxa $\\hat y$.\n",
    "\n",
    "### Actualitzar el vector de pesos\n",
    "\n",
    "L'actualització del vector de pesos $w$ es pot expressar de la següent manera:\n",
    "\n",
    "$$w = w + \\Delta w$$\n",
    "\n",
    "On el valor de $\\Delta w_j$ es defineix com el gradient negatiu multiplicat pel rati  d'aprenentage $\\eta$:\n",
    "\n",
    "$$\\Delta w = -\\eta \\nabla J (w)$$\n",
    "\n",
    "Cal tenir en compte que per calcular el gradient de la funció de cost s'ha de calcular la seva derivada parcial.\n",
    "\n",
    "Segons quina sigui la nostra política d'actualització:\n",
    "\n",
    "* **Batch gradient:** En lloc d'actualitzar els pesos a cada exemple (com a l'algorisme de Rosenblatt) aquests s'actualitzen un cop per tot el conjunt d'entrenament a cada iteració de l'algorisme. Tot el còmput es pot realitzar mitjançant una multiplicació de matrius.\n",
    "\n",
    "$$ \\Delta w = \\eta (y - \\phi(z))x $$\n",
    "\n",
    "* **Stochastic gradient descent** (SGD): Actualitza els pesos a cada mostra del conjunt d'entrenament, aconseguint la convergència al valor mínim més ràpid, a causa del major rati d'actualització dels pesos. Per obtenir bons resultats  és important que l'ordre en què computem les mostres del conjunt d'entrenament sigui aleatori a cada iteració per  evitar cicles:\n",
    "\n",
    "\n",
    "$$ \\Delta w = \\eta \\sum_i(y^{(i)} - \\phi(z^{(i)}))x^{(i)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8f11d",
   "metadata": {},
   "source": [
    "### Notes finals\n",
    "\n",
    "* El descens de gradient es beneficia de treballar amb dades estandaritzades. Amb $\\mu = 0$ i $\\sigma = 1$. A scikit teniu la funció [Standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standard%20scaler#sklearn-preprocessing-standardscaler).\n",
    "* El descens de gradient Stochastic es pot emprar per fer aprenentatge _online_ ja que podem afegir nous exemples i tornar a fer un procés d'entrenament a partir dels pesos que ja teníem.\n",
    "* Existeix una alternativa mixta als dos algorismes presentats, aquesta és coneguda com a **mini-batch** learning. Aquest mètode consisteix a aplicar la tècnica de Batch gradient a petits grups d'elements del conjunt d'entrenament. D'aquesta manera aprofitam la capacitat de fer operacions matricials del Batch learning amb la capacitat d'actualitzar els pesos més ràpid del Stochastic gradient descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba186064",
   "metadata": {},
   "source": [
    " # Feina a fer\n",
    "\n",
    "\n",
    " 0. Entendre l'algorisme del SGD.\n",
    " 1. Implementar el mètode _fit_.\n",
    " 2. Fer funcionar el main amb les dues classes (ajudau-vos de la solució de la setmana passada)\n",
    " 3. **Extra:** Modificar la classe AdalineSGD per obtenir l'error quadratic mitjà a cada iteració de l'algorisme."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aprenentatge_automatic]",
   "language": "python",
   "name": "conda-env-aprenentatge_automatic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
