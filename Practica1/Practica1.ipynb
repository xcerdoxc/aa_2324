{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic:\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funció de càrrega d'imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "        \n",
    "        for image_name in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_name)\n",
    "            image = io.imread(image_path)\n",
    "            \n",
    "            # Reescalar\n",
    "            image = resize(image, target_size)\n",
    "            # Passar a grisos\n",
    "            if image.ndim == 2:\n",
    "                gray_image = image\n",
    "            else:\n",
    "                gray_image = rgb2gray(image)\n",
    "            \n",
    "            images.append(gray_image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funció HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_images(images, hog_orientations=9, hog_pixels_per_cell=(16, 16), hog_cells_per_block=(8, 8), mostrar=False):\n",
    "    hog_features = []\n",
    "    hog_images_rescaled = []\n",
    "    for image in images:\n",
    "        if(mostrar):\n",
    "            # Compute HOG features\n",
    "            hog_feature, hog_image = hog(image, orientations=hog_orientations,\n",
    "                                        pixels_per_cell=hog_pixels_per_cell,\n",
    "                                        cells_per_block=hog_cells_per_block,\n",
    "                                        block_norm='L2-Hys', visualize=True)\n",
    "            hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "            hog_images_rescaled.append(hog_image_rescaled)\n",
    "        else:\n",
    "            hog_feature = hog(image, orientations=hog_orientations,\n",
    "                                        pixels_per_cell=hog_pixels_per_cell,\n",
    "                                        cells_per_block=hog_cells_per_block,\n",
    "                                        block_norm='L2-Hys', visualize=False)\n",
    "            hog_features.append(hog_feature.flatten())\n",
    "            \n",
    "    if(mostrar):\n",
    "        return np.array(hog_features), np.array(hog_images_rescaled)\n",
    "    else:\n",
    "        return np.array(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Càrrega de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregant imatges\n",
      "(1500, 128, 128) train imatges\n",
      "(2985, 128, 128) test imatges\n"
     ]
    }
   ],
   "source": [
    "# Carregar imatges\n",
    "train_path = 'dat/train/'\n",
    "test_path = 'dat/test/'\n",
    "print(\"Carregant imatges\")\n",
    "X_train, y_train = load_images(train_path)\n",
    "print(f\"{X_train.shape} train imatges\")\n",
    "X_test, y_test = load_images(test_path)\n",
    "print(f\"{X_test.shape} test imatges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant imatges train\n",
      "(1500, 128, 128) imatges train processades\n",
      "Processant imatges test\n",
      "(2985, 128, 128) imatges test processades\n"
     ]
    }
   ],
   "source": [
    "# Processar imatges train\n",
    "print(\"Processant imatges train\")\n",
    "mostrar = False\n",
    "if(mostrar):\n",
    "    X_train_hog, hog_train_images = hog_images(X_train, mostrar=True)\n",
    "    # Mostrar hogs\n",
    "    unique_labels = np.unique(y_train)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        index = np.where(y_train == label)[0][0]\n",
    "        plt.imshow(hog_train_images[index], cmap='gray')\n",
    "        plt.title(f'HOG Image Rescaled - Label: {label}')\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    X_train_hog = hog_images(X_train, mostrar=False)\n",
    "print(f\"{X_train.shape} imatges train processades\")\n",
    "\n",
    "# Processar imatges test\n",
    "print(\"Processant imatges test\")\n",
    "X_test_hog = hog_images(X_test, mostrar=False)\n",
    "print(f\"{X_test.shape} imatges test processades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalització de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imatges escalades\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_hog)\n",
    "X_test_scaled = scaler.transform(X_test_hog)\n",
    "print(\"Imatges escalades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar PCA\n",
    "#n_components = 500\n",
    "#pca = PCA(n_components=n_components)\n",
    "#pca.fit_transform(X_train_scaled)\n",
    "#explained_variance_ratio = pca.explained_variance_ratio_\n",
    "#cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "#plt.plot(cumulative_explained_variance)\n",
    "#plt.xlabel('Number of Principal Components')\n",
    "#plt.ylabel('Cumulative Explained Variance')\n",
    "#plt.show()\n",
    "\n",
    "#pca = PCA()\n",
    "#pca.fit_transform(X_train_scaled)\n",
    "#\n",
    "## Calculate the cumulative explained variance\n",
    "#cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "#\n",
    "## Find the number of components that capture at least 92% of the variance\n",
    "#desired_explained_variance = 0.92\n",
    "#n_components_92 = np.argmax(cumulative_explained_variance >= desired_explained_variance) + 1\n",
    "#\n",
    "#print(f\"Number of components to capture at least 92% of the variance: {n_components_92}\")\n",
    "\n",
    "# PCA per 359 components (0.92% de components que expliquen sa variança)\n",
    "#pca = PCA(n_components=359)\n",
    "#X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "#X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament i test dels SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], # Parametre de regularitzacio\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.001, 0.01, 0.1] # Coeficient de Kernel\n",
    "}\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Dataset amb el millor estimador\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "model_path = 'dat/best_svm_model.joblib'\n",
    "joblib.dump(best_svm_model, model_path)\n",
    "\n",
    "best_svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Model entrenat\")\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluació model\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model entrenat\n",
      "Confusion matrix:\n",
      " [[ 51   4   0   3   1   0   5   0   0   2  10   0  11  28   1]\n",
      " [  7  72   0   2   1   1   2   0   0   1   7   7   8   7   0]\n",
      " [  2   2 217   7   1   3   0  39   7   9   2   0   0   0  21]\n",
      " [  3   2  11 111   1   5  16   3  12   1   5  19   4  12  10]\n",
      " [  1   1   1   6 147   5   3   0   0   2  16   4   3   2   1]\n",
      " [  1   0   2   1   2 115   3   0   3   0   4   8   1   1   0]\n",
      " [  5  11   1   9   1   1 178   1   3   0  23   6   4   5   8]\n",
      " [  0   1  40   0   0   1   0 201   1  11   4   0   0   0   1]\n",
      " [  0   0   3   5   1   0   0   0 193   0   0   0   0   0  26]\n",
      " [  1   2   7   3   2   0   0  12   0 122   1   6   0   0   4]\n",
      " [  5  12  14  16   8   4  39   5   4   5  64  16   4   7   8]\n",
      " [  1  16   1  11   7   5  20   6   1   2   8 118   6   6   0]\n",
      " [ 13   8   0   3   0   1   5   2   0   1   5   1  53  17   1]\n",
      " [ 19   4   3  11   2   1   7   1   1   0   5   4  15 116   0]\n",
      " [  2   0  29   1   0   0   2   6  10  10   3   0   0   0 211]]\n",
      "Accuracy:  0.6596314907872697\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train_hog, y_train)\n",
    "print(\"Model entrenat\")\n",
    "y_pred = svm.predict(X_test_hog)\n",
    "\n",
    "# Evaluació model\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear')\n",
    "#svm.fit(X_train_scaled, y_train)\n",
    "#print(\"Model entrenat\")\n",
    "#y_pred = svm.predict(X_test_scaled)\n",
    "#\n",
    "## Evaluate the Model\n",
    "#cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Polinomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='poly')\n",
    "#svm.fit(X_train_scaled, y_train)\n",
    "#print(\"Model entrenat\")\n",
    "#y_pred = svm.predict(X_test_scaled)\n",
    "#\n",
    "## Evaluate the Model\n",
    "#cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
