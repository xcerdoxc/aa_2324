{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic:\n",
    "\n",
    "### Autors:\n",
    "- Francisco Cerdó Bibiloni\n",
    "- Gerard Mediana Martorell\n",
    "\n",
    "# 1. Introcucció\n",
    "\n",
    "En aquesta practica realitzarem una classificació amb més d'una classe. Per realitzar-ho ho farem el dataset de Paisatjes. El dataset consisteix amb diferents paisatjes classificats en 14 classes diferents. \n",
    "\n",
    "# 2. Tractament de les dades\n",
    "    - Explicar els diferents filtros que realitzam, error amb el dataset inicial i cal modificarlo \n",
    "# 3. Experiments realitzats\n",
    "    - Diferentes dades obtengundes i models procesats amb i fora filtros\n",
    "# 4. Anàlisi dels resultats i conclusions.\n",
    "    -Dades obtengundes\n",
    "# 5. Tasques realitzades per els membres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funció de càrrega d'imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "        \n",
    "        for image_name in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_name)\n",
    "            image = io.imread(image_path)\n",
    "            \n",
    "            # Reescalar\n",
    "            image = resize(image, target_size)\n",
    "            # Passar a grisos\n",
    "            if image.ndim == 2:\n",
    "                gray_image = image\n",
    "            else:\n",
    "                gray_image = rgb2gray(image)\n",
    "            \n",
    "            images.append(gray_image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funció HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_images(images, hog_orientations=9, hog_pixels_per_cell=(16, 16), hog_cells_per_block=(8, 8), mostrar=False):\n",
    "    hog_features = []\n",
    "    hog_images_rescaled = []\n",
    "    for image in images:\n",
    "        if(mostrar):\n",
    "            # Compute HOG features\n",
    "            hog_feature, hog_image = hog(image, orientations=hog_orientations,\n",
    "                                        pixels_per_cell=hog_pixels_per_cell,\n",
    "                                        cells_per_block=hog_cells_per_block,\n",
    "                                        block_norm='L2-Hys', visualize=True)\n",
    "            hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "            hog_images_rescaled.append(hog_image_rescaled)\n",
    "        else:\n",
    "            hog_feature = hog(image, orientations=hog_orientations,\n",
    "                                        pixels_per_cell=hog_pixels_per_cell,\n",
    "                                        cells_per_block=hog_cells_per_block,\n",
    "                                        block_norm='L2-Hys', visualize=False)\n",
    "            hog_features.append(hog_feature.flatten())\n",
    "            \n",
    "    if(mostrar):\n",
    "        return np.array(hog_features), np.array(hog_images_rescaled)\n",
    "    else:\n",
    "        return np.array(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Càrrega de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregant imatges\n",
      "(1500, 128, 128) train imatges\n",
      "(2985, 128, 128) test imatges\n"
     ]
    }
   ],
   "source": [
    "# Carregar imatges\n",
    "train_path = 'dat/train/'\n",
    "test_path = 'dat/test/'\n",
    "print(\"Carregant imatges\")\n",
    "X_train, y_train = load_images(train_path)\n",
    "print(f\"{X_train.shape} train imatges\")\n",
    "X_test, y_test = load_images(test_path)\n",
    "print(f\"{X_test.shape} test imatges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant imatges train\n",
      "(1500, 128, 128) imatges train processades\n",
      "Processant imatges test\n",
      "(2985, 128, 128) imatges test processades\n"
     ]
    }
   ],
   "source": [
    "# Processar imatges train\n",
    "print(\"Processant imatges train\")\n",
    "mostrar = False\n",
    "if(mostrar):\n",
    "    X_train_hog, hog_train_images = hog_images(X_train, mostrar=True)\n",
    "    # Mostrar hogs\n",
    "    unique_labels = np.unique(y_train)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        index = np.where(y_train == label)[0][0]\n",
    "        plt.imshow(hog_train_images[index], cmap='gray')\n",
    "        plt.title(f'HOG Image Rescaled - Label: {label}')\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    X_train_hog = hog_images(X_train, mostrar=False)\n",
    "print(f\"{X_train.shape} imatges train processades\")\n",
    "\n",
    "# Processar imatges test\n",
    "print(\"Processant imatges test\")\n",
    "X_test_hog = hog_images(X_test, mostrar=False)\n",
    "print(f\"{X_test.shape} imatges test processades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalització de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imatges escalades\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_hog)\n",
    "X_test_scaled = scaler.transform(X_test_hog)\n",
    "print(\"Imatges escalades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Xisco Cerdó\\Desktop\\aa_2324\\Practica1\\Practica1.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Mostrar PCA\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n_components \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39mn_components)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pca\u001b[39m.\u001b[39mfit_transform(X_train_scaled)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m explained_variance_ratio \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mexplained_variance_ratio_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "# Mostrar PCA\n",
    "n_components = 500\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit_transform(X_train_scaled)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "plt.plot(cumulative_explained_variance)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.show()\n",
    "\n",
    "#pca = PCA()\n",
    "#pca.fit_transform(X_train_scaled)\n",
    "#\n",
    "## Calculate the cumulative explained variance\n",
    "#cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "#\n",
    "## Find the number of components that capture at least 92% of the variance\n",
    "#desired_explained_variance = 0.92\n",
    "#n_components_92 = np.argmax(cumulative_explained_variance >= desired_explained_variance) + 1\n",
    "#\n",
    "#print(f\"Number of components to capture at least 92% of the variance: {n_components_92}\")\n",
    "\n",
    "# PCA per 359 components (0.92% de components que expliquen sa variança)\n",
    "#pca = PCA(n_components=359)\n",
    "#X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "#X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament i test dels SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Xisco Cerdó\\Desktop\\aa_2324\\Practica1\\Practica1.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m svm \u001b[39m=\u001b[39m SVC()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m], \u001b[39m# Parametre de regularitzacio\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m] \u001b[39m# Coeficient de Kernel\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m }\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xisco%20Cerd%C3%B3/Desktop/aa_2324/Practica1/Practica1.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(svm, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,, 1.5 , 10], # Parametre de regularitzacio\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.001, 0.01, 0.1] # Coeficient de Kernel\n",
    "}\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Dataset amb el millor estimador\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "model_path = 'dat/best_svm_model.joblib'\n",
    "joblib.dump(best_svm_model, model_path)\n",
    "\n",
    "best_svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Model entrenat\")\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluació model\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], # Parametre de regularitzacio\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.001, 0.01, 0.1] # Coeficient de Kernel\n",
    "}\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Dataset amb el millor estimador\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "model_path = 'dat/best_svm_model.joblib'\n",
    "joblib.dump(best_svm_model, model_path)\n",
    "\n",
    "best_svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Model entrenat\")\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluació model\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model entrenat\n",
      "Confusion matrix:\n",
      " [[ 51   5   0   3   1   0   7   0   0   2   8   0  14  24   1]\n",
      " [  7  70   0   2   1   1   2   0   0   1   8   8   8   7   0]\n",
      " [  2   2 220   5   2   3   0  40   9   7   2   0   0   0  18]\n",
      " [  4   1  10 111   1   5  15   5  13   1   7  16   6  10  10]\n",
      " [  1   1   1   6 149   4   2   0   0   2  16   4   3   2   1]\n",
      " [  0   0   2   1   1 117   3   0   2   0   5   8   1   1   0]\n",
      " [  6  10   1   6   1   1 183   1   4   0  23   5   3   4   8]\n",
      " [  0   1  36   0   0   1   0 206   1  10   3   0   0   0   2]\n",
      " [  0   0   5   5   1   0   0   0 195   0   0   0   0   0  22]\n",
      " [  1   2   7   3   2   0   0  11   0 124   1   6   0   0   3]\n",
      " [  5  12  10  17   8   6  38   5   6   5  63  17   5   7   7]\n",
      " [  1  15   2  14   7   5  20   3   1   2   8 119   6   5   0]\n",
      " [ 13   7   0   5   0   1   5   3   0   1   5   1  54  14   1]\n",
      " [ 30   5   3  11   3   1   7   0   1   1   7   4  16 100   0]\n",
      " [  2   0  31   0   0   0   2   5  13   8   2   0   0   0 211]]\n",
      "Accuracy:  0.6609715242881072\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1.5, kernel='rbf')\n",
    "svm.fit(X_train_hog, y_train)\n",
    "print(\"Model entrenat\")\n",
    "y_pred = svm.predict(X_test_hog)\n",
    "\n",
    "# Evaluació model\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cf_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
